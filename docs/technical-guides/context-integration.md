# Context Integration with AI Service

This document describes how PromptContextManager integrates with AIPromptProcessor and leverages ContextBuilder to format context as markdown.

## Integration Pattern

Context flows through template variables:
1. PromptContextManager generates context using ContextBuilder to format it as markdown.
2. The generated markdown context is passed as the `{{context}}` template variable.
3. AIPromptProcessor replaces the variable with the actual context.
4. The final prompt is sent to GeminiClient.

## Leveraging ContextBuilder for Markdown

PromptContextManager now utilizes the ContextBuilder class to structure and format the various context elements (world, character, events, situation) into a coherent markdown string. This ensures that the context provided to the AI is well-organized and easy to parse, improving the quality of the AI's responses.

The ContextBuilder handles the specific markdown formatting for each type of context data, such as using headings, lists, and key-value pairs where appropriate.

### Example Markdown Output

```markdown
# World: Example World

## Description:
A small, peaceful village nestled in a valley.

## Key Locations:
- Town Square
- Old Mill

# Character: Example Character

## Name:
Anya

## Description:
A young adventurer with a kind heart.

## Inventory:
- Map
- Sword

## Recent Events:
- A mysterious traveler arrived in the village.
- The old mill's wheel stopped turning.

Current Situation: The villagers are worried about the mill.
```

## Example Usage

```typescript
// 1. Generate context using PromptContextManager (which uses ContextBuilder internally)
const contextResult = await contextManager.generateContext({
  world: worldData,
  character: characterData,
  recentEvents: recentEventsData,
  currentSituation: currentSituationData,
  tokenLimit: 1000
});

// The contextResult.context now contains the markdown string generated by ContextBuilder

// 2. Create template with context variable
const template = {
  id: 'narrative-with-context',
  type: PromptType.NARRATIVE,
  content: '{{context}}\n\nGenerate a narrative based on the provided context.',
  variables: [{ name: 'context', description: 'World, character, events, and situation context formatted as markdown' }]
};

// 3. Process and send to AI
const result = await aiProcessor.processAndSend('narrative-with-context', {
  context: contextResult.context
});
```

## Token Monitoring

Basic MVP level tracking:
- Context token count reported by PromptContextManager
- Final prompt/completion tokens tracked by AIPromptProcessor
- No complex aggregation or optimization

## Test Coverage

Three integration test suites verify:
1. Context passes correctly to AI
2. Token usage monitoring works
3. Edge cases (null/missing data) handled
